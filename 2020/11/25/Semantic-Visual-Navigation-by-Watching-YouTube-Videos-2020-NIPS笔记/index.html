
<!DOCTYPE html>
<html lang="en">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Jthonlab">
    <title>Semantic Visual Navigation by Watching YouTube Videos. 2020 NIPS笔记 - Jthonlab</title>
    <meta name="author" content="Jthon lab">
    
        <meta name="keywords" content="Reinforcement Learning,Navigation">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jthon lab","sameAs":["https://github.com/Jthon-lab?tab=repositories"],"image":"avatar_duck.jpg"},"articleBody":"这篇文章的主要创新点在于通过采集无标签的YouTube视频，来学习出不同类别物体之间的关联性，文中称作semantic cues来辅助进行导航。YouTube视频是无标签的，通过这样的数据来学习这样长期的导航策略会面临如下挑战：(1) 由于视频无action标签，所以就不能使用类似Learning from demonstration或者Imitation Learning类似的技巧来学习(2) 由于想要解决的是导航任务，而视频数据本身并不提供任何与目标相关的信息(3) 视频中的行动序列往往并不是最优路径，这本身也不符合Learning from demonstration或者是inverse reinforcement learning的假设。\n\n\nTask Defination and Assumption本文要解决的是ObjectGoal Navigation任务，指定一个目标类别，智能体应该尽快在一个新的环境中找到这个类别。本文所能获得的输入信息包括了30°视角的RGB-D图像信息，同时作者进行的一个比较重要的假设是能够通过SLAM获得一个比较准确的位置估计$\\hat{x}_{t}$。Actions包括了MoveAhead 25cm， RotateLeft 30°， RotateRight 30°，Stop四个动作。目标类别包括了bed, chair, couch, dining table, toilet五种。\nSimulators and Dataset本文的数据集主要来自两方面，一个是从YouTube上采集的视频数据集，YouTube House Tours Dataset,包括了来自1387个视频中共计119小时的视频序列。每隔1.5秒进行采样，最终获得了550K 组$(I_{t},I_{t+1})$。另外一组数据集来自Gibson数据集。\nNavigation Policy这篇文章的导航策略分为两层，包括一个High-level Policy和一个Low-level Policy。Low-level Policy是通过传统的SLAM来实现的，通过给定High-level Policy指定的目标位置，和当前所在的位置，通过在occupancy map上进行路径规划而得到行动。High-level Policy用来选择一个promising的方向进行后续行动，具体来说，智能体首先在原地进行12次旋转的行动，因此能够获得12张不同角度的图片，然后分别对这12张图片进行打分，打分的具体细节后面再介绍，然后选择一个分数最高的方向，然后由于本篇工作中实时对位置进行估计，因此，以当前位置为参考点，沿着分数最高的方向，选择一个距离合适的位置，作为目标位置sub-goal，然后把这个目标位置传给Low-level Policy形成导航策略。由于在进行promising direction选择的时候需要采取12次行动，比较耗时，因此只有在到达上一次的sub-goal后，再重新进行direction的选择。整个决策的过程如Figure 1和Figure 2所示。\nFigure 1.Visualization of Navigation Policy\n\n\nFigure 2.Architecture of Navigation Policy\n\nValue Learning from Videos这篇文章的主要创新点就在于如何通过无标签的Videos来得到针对某个导航目标下不同的图片的分数$f(I,c)$, I表示图片，c表示目标类别。这篇文章希望通过强化学习的值函数来表达$f(I,c)$，但是比较大的问题是，在值函数的学习中需要四元组$(s_{t},a,r,s_{t+1})$, 而视频只有$s_{t}$和$s_{t+1}$。为了得到$a_{t}$，作者使用Gibson数据集，让智能体采用random policy和环境进行交互，然后学习inverse dynamic model也就是根据$(I_{t},I_{t+1})$来对行动进行预测，使用这个inverse dynamic model就能够对视频序列的action进行label。inverse dynamic model的具体细节为：使用预训练好的ResNet-18对图片进行特征提取，然后把连续两帧的特征拼接起来进行行动预测，使用cross-entropy loss。为了得到reward，作者使用一个训练好的Mask-RCNN来对目标类别进行预测，若当前图片中出现了目标类别c,设置reward=1，否则为0。从而获得了四元组$(s_{t},a,r,s_{t+1})$。接下来使用Q-learning的方法对视频序列进行学习，学习到Q-function:$Q(I_{t},c,a)$，最终根据Q-function来定义$f(I,c)$可采用平均或者是最大值等方式。最终针对图片的完整打分如下：$$ f_{comb}(I,c) = \\lambda_{1}f(I,c) + \\lambda_{2}I_{&gt;0.5}[D_{coco}(I,c)]\\cdot (1+D_{coco}(I,c)) + 0.05\\lambda_{3} max(10-d,0) $$第一项就是上述提到的$f(I,c)$,第二项是检测当前图片I中是否存在目标种类c的一个打分，检测结果置信度越高，分数越高，第三项用来衡量空间一致性的分数，用来保证选择出的subgoal距离自己是比较近的。因为在进行打分的时候，high-level policy对每一个节点存储的12张图片，总共12N张图片进行打分，那么为了不选择那些位置距离自己较远的结点，所以第三项空间一致性也是必不可少的。 Value learning的过程如Figure 3所示。\nFigure 3.Architecture of Value Learning from Videos\n\nExperiments通过对比了几种不同的Baselines，验证了他们的算法表现是最好的。 实验结果如Figure 4所示。\nFigure 3.Experiments Result\n","dateCreated":"2020-11-25T13:11:41+08:00","dateModified":"2020-11-25T05:20:03+08:00","datePublished":"2020-11-25T13:11:41+08:00","description":"这篇文章的主要创新点在于通过采集无标签的YouTube视频，来学习出不同类别物体之间的关联性，文中称作semantic cues来辅助进行导航。YouTube视频是无标签的，通过这样的数据来学习这样长期的导航策略会面临如下挑战：(1) 由于视频无action标签，所以就不能使用类似Learning from demonstration或者Imitation Learning类似的技巧来学习(2) 由于想要解决的是导航任务，而视频数据本身并不提供任何与目标相关的信息(3) 视频中的行动序列往往并不是最优路径，这本身也不符合Learning from demonstration或者是inverse reinforcement learning的假设。","headline":"Semantic Visual Navigation by Watching YouTube Videos. 2020 NIPS笔记","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2020/11/25/Semantic-Visual-Navigation-by-Watching-YouTube-Videos-2020-NIPS%E7%AC%94%E8%AE%B0/"},"publisher":{"@type":"Organization","name":"Jthon lab","sameAs":["https://github.com/Jthon-lab?tab=repositories"],"image":"avatar_duck.jpg","logo":{"@type":"ImageObject","url":"avatar_duck.jpg"}},"url":"http://yoursite.com/2020/11/25/Semantic-Visual-Navigation-by-Watching-YouTube-Videos-2020-NIPS%E7%AC%94%E8%AE%B0/"}</script>
    <meta name="description" content="这篇文章的主要创新点在于通过采集无标签的YouTube视频，来学习出不同类别物体之间的关联性，文中称作semantic cues来辅助进行导航。YouTube视频是无标签的，通过这样的数据来学习这样长期的导航策略会面临如下挑战：(1) 由于视频无action标签，所以就不能使用类似Learning from demonstration或者Imitation Learning类似的技巧来学习(2)">
<meta property="og:type" content="blog">
<meta property="og:title" content="Semantic Visual Navigation by Watching YouTube Videos. 2020 NIPS笔记">
<meta property="og:url" content="http://yoursite.com/2020/11/25/Semantic-Visual-Navigation-by-Watching-YouTube-Videos-2020-NIPS%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Jthonlab">
<meta property="og:description" content="这篇文章的主要创新点在于通过采集无标签的YouTube视频，来学习出不同类别物体之间的关联性，文中称作semantic cues来辅助进行导航。YouTube视频是无标签的，通过这样的数据来学习这样长期的导航策略会面临如下挑战：(1) 由于视频无action标签，所以就不能使用类似Learning from demonstration或者Imitation Learning类似的技巧来学习(2)">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/Nav1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/Nav2.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/ValueLearning.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/Experiments.png">
<meta property="article:published_time" content="2020-11-25T05:11:41.000Z">
<meta property="article:modified_time" content="2020-11-24T21:20:03.352Z">
<meta property="article:author" content="Jthon lab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/Nav1.png">
    
    
        
    
    
        <meta property="og:image" content="http://yoursite.com/assets/images/avatar_duck.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-ahqseqdv7x8dyzqwhdknvcrrww0emg3sjq868izfcneq33qr7ode8shlnqqr.min.css">

    <!--STYLES END--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

    

    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/%20"
            aria-label=""
        >
            Jthonlab
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/avatar_duck.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/avatar_duck.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Jthon lab</h4>
                
                    <h5 class="sidebar-profile-bio"><p>author.bio</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/Jthon-lab?tab=repositories"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaOut
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-center">
    
        <h1 class="post-title">
            Semantic Visual Navigation by Watching YouTube Videos. 2020 NIPS笔记
        </h1>
    
    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>这篇文章的主要创新点在于通过采集无标签的YouTube视频，来学习出不同类别物体之间的关联性，文中称作semantic cues来辅助进行导航。YouTube视频是无标签的，通过这样的数据来学习这样长期的导航策略会面临如下挑战：<br>(1) 由于视频无action标签，所以就不能使用类似Learning from demonstration或者Imitation Learning类似的技巧来学习<br>(2) 由于想要解决的是导航任务，而视频数据本身并不提供任何与目标相关的信息<br>(3) 视频中的行动序列往往并不是最优路径，这本身也不符合Learning from demonstration或者是inverse reinforcement learning的假设。</p>
<a id="more"></a>

<h2 id="Task-Defination-and-Assumption"><a href="#Task-Defination-and-Assumption" class="headerlink" title="Task Defination and Assumption"></a>Task Defination and Assumption</h2><p>本文要解决的是ObjectGoal Navigation任务，指定一个目标类别，智能体应该尽快在一个新的环境中找到这个类别。本文所能获得的输入信息包括了30°视角的RGB-D图像信息，同时作者进行的一个比较重要的假设是能够通过SLAM获得一个比较准确的位置估计$\hat{x}_{t}$。Actions包括了MoveAhead 25cm， RotateLeft 30°， RotateRight 30°，Stop四个动作。目标类别包括了bed, chair, couch, dining table, toilet五种。</p>
<h2 id="Simulators-and-Dataset"><a href="#Simulators-and-Dataset" class="headerlink" title="Simulators and Dataset"></a>Simulators and Dataset</h2><p>本文的数据集主要来自两方面，一个是从YouTube上采集的视频数据集，YouTube House Tours Dataset,包括了来自1387个视频中共计119小时的视频序列。每隔1.5秒进行采样，最终获得了550K 组$(I_{t},I_{t+1})$。另外一组数据集来自Gibson数据集。</p>
<h2 id="Navigation-Policy"><a href="#Navigation-Policy" class="headerlink" title="Navigation Policy"></a>Navigation Policy</h2><p>这篇文章的导航策略分为两层，包括一个High-level Policy和一个Low-level Policy。Low-level Policy是通过传统的SLAM来实现的，通过给定High-level Policy指定的目标位置，和当前所在的位置，通过在occupancy map上进行路径规划而得到行动。High-level Policy用来选择一个promising的方向进行后续行动，具体来说，智能体首先在原地进行12次旋转的行动，因此能够获得12张不同角度的图片，然后分别对这12张图片进行打分，打分的具体细节后面再介绍，然后选择一个分数最高的方向，然后由于本篇工作中实时对位置进行估计，因此，以当前位置为参考点，沿着分数最高的方向，选择一个距离合适的位置，作为目标位置sub-goal，然后把这个目标位置传给Low-level Policy形成导航策略。由于在进行promising direction选择的时候需要采取12次行动，比较耗时，因此只有在到达上一次的sub-goal后，再重新进行direction的选择。整个决策的过程如Figure 1和Figure 2所示。<br><img src="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/Nav1.png" alt="Nav1"></p>
<center><b>Figure 1.Visualization of Navigation Policy</b></center>

<p><img src="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/Nav2.png" alt="Nav2"></p>
<center><b>Figure 2.Architecture of Navigation Policy</b></center>

<h2 id="Value-Learning-from-Videos"><a href="#Value-Learning-from-Videos" class="headerlink" title="Value Learning from Videos"></a>Value Learning from Videos</h2><p>这篇文章的主要创新点就在于如何通过无标签的Videos来得到针对某个导航目标下不同的图片的分数$f(I,c)$, I表示图片，c表示目标类别。这篇文章希望通过强化学习的值函数来表达$f(I,c)$，但是比较大的问题是，在值函数的学习中需要四元组$(s_{t},a,r,s_{t+1})$, 而视频只有$s_{t}$和$s_{t+1}$。为了得到$a_{t}$，作者使用Gibson数据集，让智能体采用random policy和环境进行交互，然后学习inverse dynamic model也就是根据$(I_{t},I_{t+1})$来对行动进行预测，使用这个inverse dynamic model就能够对视频序列的action进行label。inverse dynamic model的具体细节为：使用预训练好的ResNet-18对图片进行特征提取，然后把连续两帧的特征拼接起来进行行动预测，使用cross-entropy loss。为了得到reward，作者使用一个训练好的Mask-RCNN来对目标类别进行预测，若当前图片中出现了目标类别c,设置reward=1，否则为0。从而获得了四元组$(s_{t},a,r,s_{t+1})$。接下来使用Q-learning的方法对视频序列进行学习，学习到Q-function:$Q(I_{t},c,a)$，最终根据Q-function来定义$f(I,c)$可采用平均或者是最大值等方式。最终针对图片的完整打分如下：<br>$$ f_{comb}(I,c) = \lambda_{1}f(I,c) + \lambda_{2}I_{&gt;0.5}[D_{coco}(I,c)]\cdot (1+D_{coco}(I,c)) + 0.05\lambda_{3} max(10-d,0) $$<br>第一项就是上述提到的$f(I,c)$,第二项是检测当前图片I中是否存在目标种类c的一个打分，检测结果置信度越高，分数越高，第三项用来衡量空间一致性的分数，用来保证选择出的subgoal距离自己是比较近的。因为在进行打分的时候，high-level policy对每一个节点存储的12张图片，总共12N张图片进行打分，那么为了不选择那些位置距离自己较远的结点，所以第三项空间一致性也是必不可少的。 Value learning的过程如Figure 3所示。<br><img src="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/ValueLearning.png" alt="ValueLearning"></p>
<center><b>Figure 3.Architecture of Value Learning from Videos</b></center>

<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>通过对比了几种不同的Baselines，验证了他们的算法表现是最好的。 实验结果如Figure 4所示。<br><img src="https://raw.githubusercontent.com/Jthon-lab/image_repo/master/2020.11.25/Experiments.png" alt="ValueLearning"></p>
<center><b>Figure 3.Experiments Result</b></center>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
        
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 Jthon lab. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/avatar_duck.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Jthon lab</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>RL</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Nanjing,China
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-spuaps2qplesxnme8e5wnd40hjkfzjjsqbnwhi8zohmoqbez3cm8pj5m7ejx.min.js"></script>

<!--SCRIPTS END-->





    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
