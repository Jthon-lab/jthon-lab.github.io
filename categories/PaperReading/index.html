
<!DOCTYPE html>
<html lang="en">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Jthonlab">
    <title>Category: PaperReading - Jthonlab</title>
    <meta name="author" content="Jthon lab">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta property="og:type" content="blog">
<meta property="og:title" content="Jthonlab">
<meta property="og:url" content="http://yoursite.com/categories/PaperReading/index.html">
<meta property="og:site_name" content="Jthonlab">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Jthon lab">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="http://yoursite.com/assets/images/avatar_duck.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-ahqseqdv7x8dyzqwhdknvcrrww0emg3sjq868izfcneq33qr7ode8shlnqqr.min.css">

    <!--STYLES END--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

    

    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/%20"
            aria-label=""
        >
            Jthonlab
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/avatar_duck.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/avatar_duck.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Jthon lab</h4>
                
                    <h5 class="sidebar-profile-bio"><p>author.bio</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/Jthon-lab?tab=repositories"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2020/11/13/Curriculum-guided-Hindsight-Experience-Replay-2019-NIPS%E7%AC%94%E8%AE%B0/"
                            aria-label=": Curriculum-guided Hindsight Experience Replay. 2019 NIPS笔记"
                        >
                            Curriculum-guided Hindsight Experience Replay. 2019 NIPS笔记
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2020-11-13T10:42:41+08:00">
	
		    Nov 13, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/PaperReading/">PaperReading</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>这篇文章主要是针对Hindsight Experience Replay的改进，HER在重新选择goal的时候采用了随机采样的方式，而不同的goal对于真正任务的goal所能提供的学习的信息是不一样的，随机采样的方式显然是一种比较简单的做法。这篇文章提出了CHER，通过在Replay buffer中选择一部分能够保证diversity并且距离真正任务的goal较近的子集作为目标，实现了exploration-exploitation的trade-off。</p>
                    
                        <a
                            href="/2020/11/13/Curriculum-guided-Hindsight-Experience-Replay-2019-NIPS%E7%AC%94%E8%AE%B0/"
                            class="postShorten-excerpt_link link"
                            aria-label=": Curriculum-guided Hindsight Experience Replay. 2019 NIPS笔记"
                        >
                            Continue reading
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2020/11/08/Learning-Exploration-Policies-for-Navigation-2019-ICLR/"
                            aria-label=": Learning Exploration Policies for Navigation. 2019 ICLR 笔记"
                        >
                            Learning Exploration Policies for Navigation. 2019 ICLR 笔记
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2020-11-08T20:05:41+08:00">
	
		    Nov 08, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/PaperReading/">PaperReading</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>这篇文章旨在提升新场景导航中Exploration效率问题，导航本身是一个sparse-reward的场景，如果没有一些额外的帮助搜索的机制的话会给强化学习带来困难，有一些工作使用了辅助任务来提升学习的效率，如UNREAL，还有Learning to Navigate in Complex Environments等文章。这篇文章主要的创新点在于将SLAM获取的环境地图与第一人称视角的信息相结合，提升了在新场景中的exploration效率。</p>
                    
                        <a
                            href="/2020/11/08/Learning-Exploration-Policies-for-Navigation-2019-ICLR/"
                            class="postShorten-excerpt_link link"
                            aria-label=": Learning Exploration Policies for Navigation. 2019 ICLR 笔记"
                        >
                            Continue reading
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2020/10/19/Goal-Aware-Prediction-Learning-to-Model-What-Matters-2020.%20ICML%E7%AC%94%E8%AE%B0/"
                            aria-label=": Goal Aware Prediction Learning to Model What Matters. 2020 ICML 笔记"
                        >
                            Goal Aware Prediction Learning to Model What Matters. 2020 ICML 笔记
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2020-10-19T21:03:41+08:00">
	
		    Oct 19, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/PaperReading/">PaperReading</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>这篇文章要做的仍然是如何学习一个更好的环境的dynamics，并且使用学习到的dynamics与planning进行结合来得到更好的强化学习的表现。<br>这篇文章的主要贡献思路在于对预测误差进行一个重分布，即希望模型对距离goal较近的state进行比较精确的预测，而对那些和goal无关的状态，即使得到的预测结果比较差也认为是可以接受的。那么作者认为这样的想法可以带来如下两个优点：<br>(1) 一个场景里许多的元素是与goal不相关的<br>(2) 距离goal比较近的状态应该更容易预测因为误差接近于0</p>
                    
                        <a
                            href="/2020/10/19/Goal-Aware-Prediction-Learning-to-Model-What-Matters-2020.%20ICML%E7%AC%94%E8%AE%B0/"
                            class="postShorten-excerpt_link link"
                            aria-label=": Goal Aware Prediction Learning to Model What Matters. 2020 ICML 笔记"
                        >
                            Continue reading
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2020/09/04/Evolution-Guided-Policy-Gradient-in-Reinforcement.%202018%20NIPS%E7%AC%94%E8%AE%B0/"
                            aria-label=": Evolution-Guided Policy Gradient in Reinforcement Learning. 2018 NIPS 笔记"
                        >
                            Evolution-Guided Policy Gradient in Reinforcement Learning. 2018 NIPS 笔记
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2020-09-04T23:02:41+08:00">
	
		    Sep 04, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/PaperReading/">PaperReading</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>这篇文章的思想非常有意思，它将进化算法与深度强化学习结合了起来，发表于NIPS 2018, 这篇文章的出发点在于深度强化学习会面临如下几个挑战：<br>(1) <strong>Temporal credit assignment with sparse rewards</strong>,即在sparse reward的场景下，评价行为的好坏变得更加困难。<br>(2) <strong>Lack of effective exploration</strong>,如何高效探索防止陷入局部最优一直是强化学习的一个问题。<br>(3) <strong>Brittle convergence properties that are extremely sensitive to hyperparameters</strong>,同样强化学习对超参数非常敏感而且不容易收敛。<br>这篇文章通过将传统的优化算法EA和DRL相结合的方式，使得算法性能超出了原先的EA与DRL算法。</p>
                    
                        <a
                            href="/2020/09/04/Evolution-Guided-Policy-Gradient-in-Reinforcement.%202018%20NIPS%E7%AC%94%E8%AE%B0/"
                            class="postShorten-excerpt_link link"
                            aria-label=": Evolution-Guided Policy Gradient in Reinforcement Learning. 2018 NIPS 笔记"
                        >
                            Continue reading
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2020/08/15/On%20Bouns-Based%20Exploration%20methods%20in%20the%20arcade%20learning%20environment.%202020%20ICLR%E7%AC%94%E8%AE%B0/"
                            aria-label=": On Bouns-Based Exploration methods in the arcade learning environment. 2020 ICLR 笔记"
                        >
                            On Bouns-Based Exploration methods in the arcade learning environment. 2020 ICLR 笔记
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2020-08-15T15:55:20+08:00">
	
		    Aug 15, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/PaperReading/">PaperReading</a>, <a class="category-link" href="/categories/PaperReading/Exploration/">Exploration</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>这是一篇针对强化学习领域exploration的一篇综述性文章，这篇文章主要将近些年的基于bouns的exploration的方法进行了一个综合比较，其中包括了pesudo-count、ICM、RND、NoisyNet与最基础的e-greedy等exploration的机制。通过实验发现其中某些算法虽然在Hard Exploration Games如Montezuma’s Revenge中表现很优秀，但是整体的性能并没有比e-greedy高出太多，说明在exploration方面仍然有许多值得研究的问题。这篇文章发表于ICLR 2020。</p>
                    
                        <a
                            href="/2020/08/15/On%20Bouns-Based%20Exploration%20methods%20in%20the%20arcade%20learning%20environment.%202020%20ICLR%E7%AC%94%E8%AE%B0/"
                            class="postShorten-excerpt_link link"
                            aria-label=": On Bouns-Based Exploration methods in the arcade learning environment. 2020 ICLR 笔记"
                        >
                            Continue reading
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">page 1 of 1</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 Jthon lab. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/avatar_duck.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Jthon lab</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>RL</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Nanjing,China
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-spuaps2qplesxnme8e5wnd40hjkfzjjsqbnwhi8zohmoqbez3cm8pj5m7ejx.min.js"></script>

<!--SCRIPTS END-->





    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
